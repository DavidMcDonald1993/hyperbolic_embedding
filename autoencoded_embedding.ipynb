{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from gem.utils import graph_util\n",
    "\n",
    "# Load graph\n",
    "# graph = graph_util.loadGraph('gem/data/karate.edgelist')\n",
    "graph = nx.karate_club_graph().to_directed()\n",
    "\n",
    "# second level similarity\n",
    "S1 = np.array(nx.adj_matrix(graph).todense())\n",
    "S2 = cosine_similarity(S1)\n",
    "\n",
    "S = S1 + 0 * S2\n",
    "\n",
    "nodes = np.array(graph.nodes())\n",
    "weights = {(u, v): S[np.where(nodes==u)[0], np.where(nodes==v)[0]][0] for u, v in graph.edges()}\n",
    "\n",
    "nx.set_edge_attributes(graph, \"weight\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import C++ module for Graph Factorization. Reverting to python implementation. Please recompile graphFac_ext from graphFac.cpp using bjam\n",
      "\t\tIter id: 0, Objective value: 156.013, f1: 156.006, f2: 0.00649633\n",
      "\t\tIter id: 100, Objective value: 156.012, f1: 156.006, f2: 0.00610262\n",
      "\t\tIter id: 200, Objective value: 156.011, f1: 156.005, f2: 0.00576172\n",
      "\t\tIter id: 300, Objective value: 156.01, f1: 156.004, f2: 0.00546394\n",
      "\t\tIter id: 400, Objective value: 156.009, f1: 156.004, f2: 0.00520182\n",
      "\t\tIter id: 500, Objective value: 156.008, f1: 156.003, f2: 0.00496948\n",
      "\t\tIter id: 600, Objective value: 156.007, f1: 156.003, f2: 0.00476229\n",
      "\t\tIter id: 700, Objective value: 156.007, f1: 156.002, f2: 0.00457652\n",
      "\t\tIter id: 800, Objective value: 156.006, f1: 156.002, f2: 0.00440919\n",
      "\t\tIter id: 900, Objective value: 156.005, f1: 156.001, f2: 0.00425784\n",
      "\t\tIter id: 1000, Objective value: 156.005, f1: 156.001, f2: 0.00412045\n",
      "\t\tIter id: 1100, Objective value: 156.004, f1: 156, f2: 0.00399534\n",
      "\t\tIter id: 1200, Objective value: 156.004, f1: 156, f2: 0.00388107\n",
      "\t\tIter id: 1300, Objective value: 156.003, f1: 155.999, f2: 0.00377646\n",
      "\t\tIter id: 1400, Objective value: 156.003, f1: 155.999, f2: 0.00368046\n",
      "\t\tIter id: 1500, Objective value: 156.002, f1: 155.999, f2: 0.00359217\n",
      "\t\tIter id: 1600, Objective value: 156.002, f1: 155.998, f2: 0.00351082\n",
      "\t\tIter id: 1700, Objective value: 156.001, f1: 155.998, f2: 0.00343574\n",
      "\t\tIter id: 1800, Objective value: 156.001, f1: 155.998, f2: 0.00336631\n",
      "\t\tIter id: 1900, Objective value: 156.001, f1: 155.997, f2: 0.00330202\n",
      "\t\tIter id: 2000, Objective value: 156, f1: 155.997, f2: 0.00324238\n",
      "\t\tIter id: 2100, Objective value: 156, f1: 155.997, f2: 0.00318699\n",
      "\t\tIter id: 2200, Objective value: 156, f1: 155.997, f2: 0.00313547\n",
      "\t\tIter id: 2300, Objective value: 155.999, f1: 155.996, f2: 0.00308748\n",
      "\t\tIter id: 2400, Objective value: 155.999, f1: 155.996, f2: 0.00304271\n",
      "\t\tIter id: 2500, Objective value: 155.999, f1: 155.996, f2: 0.00300091\n",
      "\t\tIter id: 2600, Objective value: 155.999, f1: 155.996, f2: 0.00296181\n",
      "\t\tIter id: 2700, Objective value: 155.998, f1: 155.996, f2: 0.0029252\n",
      "\t\tIter id: 2800, Objective value: 155.998, f1: 155.995, f2: 0.00289087\n",
      "\t\tIter id: 2900, Objective value: 155.998, f1: 155.995, f2: 0.00285864\n",
      "\t\tIter id: 3000, Objective value: 155.998, f1: 155.995, f2: 0.00282835\n",
      "\t\tIter id: 3100, Objective value: 155.998, f1: 155.995, f2: 0.00279983\n",
      "\t\tIter id: 3200, Objective value: 155.998, f1: 155.995, f2: 0.00277296\n",
      "\t\tIter id: 3300, Objective value: 155.997, f1: 155.995, f2: 0.0027476\n",
      "\t\tIter id: 3400, Objective value: 155.997, f1: 155.994, f2: 0.00272364\n",
      "\t\tIter id: 3500, Objective value: 155.997, f1: 155.994, f2: 0.00270096\n",
      "\t\tIter id: 3600, Objective value: 155.997, f1: 155.994, f2: 0.00267949\n",
      "\t\tIter id: 3700, Objective value: 155.997, f1: 155.994, f2: 0.00265912\n",
      "\t\tIter id: 3800, Objective value: 155.997, f1: 155.994, f2: 0.00263977\n",
      "\t\tIter id: 3900, Objective value: 155.997, f1: 155.994, f2: 0.00262137\n",
      "\t\tIter id: 4000, Objective value: 155.997, f1: 155.994, f2: 0.00260385\n",
      "\t\tIter id: 4100, Objective value: 155.996, f1: 155.994, f2: 0.00258715\n",
      "\t\tIter id: 4200, Objective value: 155.996, f1: 155.994, f2: 0.0025712\n",
      "\t\tIter id: 4300, Objective value: 155.996, f1: 155.994, f2: 0.00255596\n",
      "\t\tIter id: 4400, Objective value: 155.996, f1: 155.994, f2: 0.00254137\n",
      "\t\tIter id: 4500, Objective value: 155.996, f1: 155.994, f2: 0.00252739\n",
      "\t\tIter id: 4600, Objective value: 155.996, f1: 155.994, f2: 0.00251397\n",
      "\t\tIter id: 4700, Objective value: 155.996, f1: 155.993, f2: 0.00250108\n",
      "\t\tIter id: 4800, Objective value: 155.996, f1: 155.993, f2: 0.00248869\n",
      "\t\tIter id: 4900, Objective value: 155.996, f1: 155.993, f2: 0.00247675\n",
      "\t\tIter id: 5000, Objective value: 155.996, f1: 155.993, f2: 0.00246524\n",
      "\t\tIter id: 5100, Objective value: 155.996, f1: 155.993, f2: 0.00245413\n",
      "\t\tIter id: 5200, Objective value: 155.996, f1: 155.993, f2: 0.00244339\n",
      "\t\tIter id: 5300, Objective value: 155.996, f1: 155.993, f2: 0.00243301\n",
      "\t\tIter id: 5400, Objective value: 155.996, f1: 155.993, f2: 0.00242295\n",
      "\t\tIter id: 5500, Objective value: 155.996, f1: 155.993, f2: 0.0024132\n",
      "\t\tIter id: 5600, Objective value: 155.996, f1: 155.993, f2: 0.00240373\n",
      "\t\tIter id: 5700, Objective value: 155.996, f1: 155.993, f2: 0.00239454\n",
      "\t\tIter id: 5800, Objective value: 155.996, f1: 155.993, f2: 0.0023856\n",
      "\t\tIter id: 5900, Objective value: 155.996, f1: 155.993, f2: 0.0023769\n",
      "\t\tIter id: 6000, Objective value: 155.996, f1: 155.993, f2: 0.00236843\n",
      "\t\tIter id: 6100, Objective value: 155.996, f1: 155.993, f2: 0.00236017\n",
      "\t\tIter id: 6200, Objective value: 155.996, f1: 155.993, f2: 0.00235211\n",
      "\t\tIter id: 6300, Objective value: 155.996, f1: 155.993, f2: 0.00234424\n",
      "\t\tIter id: 6400, Objective value: 155.996, f1: 155.993, f2: 0.00233655\n",
      "\t\tIter id: 6500, Objective value: 155.996, f1: 155.993, f2: 0.00232903\n",
      "\t\tIter id: 6600, Objective value: 155.995, f1: 155.993, f2: 0.00232167\n",
      "\t\tIter id: 6700, Objective value: 155.995, f1: 155.993, f2: 0.00231447\n",
      "\t\tIter id: 6800, Objective value: 155.995, f1: 155.993, f2: 0.00230741\n",
      "\t\tIter id: 6900, Objective value: 155.995, f1: 155.993, f2: 0.0023005\n",
      "\t\tIter id: 7000, Objective value: 155.995, f1: 155.993, f2: 0.00229372\n",
      "\t\tIter id: 7100, Objective value: 155.995, f1: 155.993, f2: 0.00228707\n",
      "\t\tIter id: 7200, Objective value: 155.995, f1: 155.993, f2: 0.00228054\n",
      "\t\tIter id: 7300, Objective value: 155.995, f1: 155.993, f2: 0.00227413\n",
      "\t\tIter id: 7400, Objective value: 155.995, f1: 155.993, f2: 0.00226783\n",
      "\t\tIter id: 7500, Objective value: 155.995, f1: 155.993, f2: 0.00226164\n",
      "\t\tIter id: 7600, Objective value: 155.995, f1: 155.993, f2: 0.00225556\n",
      "\t\tIter id: 7700, Objective value: 155.995, f1: 155.993, f2: 0.00224958\n",
      "\t\tIter id: 7800, Objective value: 155.995, f1: 155.993, f2: 0.0022437\n",
      "\t\tIter id: 7900, Objective value: 155.995, f1: 155.993, f2: 0.00223791\n",
      "\t\tIter id: 8000, Objective value: 155.996, f1: 155.993, f2: 0.00223222\n",
      "\t\tIter id: 8100, Objective value: 155.996, f1: 155.993, f2: 0.00222662\n",
      "\t\tIter id: 8200, Objective value: 155.996, f1: 155.993, f2: 0.00222111\n",
      "\t\tIter id: 8300, Objective value: 155.996, f1: 155.993, f2: 0.00221569\n",
      "\t\tIter id: 8400, Objective value: 155.996, f1: 155.993, f2: 0.00221035\n",
      "\t\tIter id: 8500, Objective value: 155.996, f1: 155.993, f2: 0.00220509\n",
      "\t\tIter id: 8600, Objective value: 155.996, f1: 155.993, f2: 0.00219991\n",
      "\t\tIter id: 8700, Objective value: 155.996, f1: 155.993, f2: 0.00219482\n",
      "\t\tIter id: 8800, Objective value: 155.996, f1: 155.993, f2: 0.0021898\n",
      "\t\tIter id: 8900, Objective value: 155.996, f1: 155.993, f2: 0.00218486\n",
      "\t\tIter id: 9000, Objective value: 155.996, f1: 155.993, f2: 0.00217999\n",
      "\t\tIter id: 9100, Objective value: 155.996, f1: 155.993, f2: 0.0021752\n",
      "\t\tIter id: 9200, Objective value: 155.996, f1: 155.993, f2: 0.00217048\n",
      "\t\tIter id: 9300, Objective value: 155.996, f1: 155.993, f2: 0.00216584\n",
      "\t\tIter id: 9400, Objective value: 155.996, f1: 155.993, f2: 0.00216126\n",
      "\t\tIter id: 9500, Objective value: 155.996, f1: 155.993, f2: 0.00215676\n",
      "\t\tIter id: 9600, Objective value: 155.996, f1: 155.993, f2: 0.00215233\n",
      "\t\tIter id: 9700, Objective value: 155.996, f1: 155.993, f2: 0.00214797\n",
      "\t\tIter id: 9800, Objective value: 155.996, f1: 155.993, f2: 0.00214368\n",
      "\t\tIter id: 9900, Objective value: 155.996, f1: 155.993, f2: 0.00213945\n"
     ]
    }
   ],
   "source": [
    "from gem.embedding.gf import GraphFactorization as gf\n",
    "\n",
    "# Instatiate the embedding method with hyperparameters\n",
    "em = gf(d=2, max_iter=10000, eta=1e-4, regu=1.0)\n",
    "\n",
    "# Learn embedding - accepts a networkx graph or file with edge list\n",
    "Y, t = em.learn_embedding(graph, edge_f=None, is_weighted=True, no_python=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, {'weight': 1.0}),\n",
       " (0, 2, {'weight': 1.0}),\n",
       " (0, 3, {'weight': 1.0}),\n",
       " (0, 4, {'weight': 1.0}),\n",
       " (0, 5, {'weight': 1.0}),\n",
       " (0, 6, {'weight': 1.0}),\n",
       " (0, 7, {'weight': 1.0}),\n",
       " (0, 8, {'weight': 1.0}),\n",
       " (0, 10, {'weight': 1.0}),\n",
       " (0, 11, {'weight': 1.0}),\n",
       " (0, 12, {'weight': 1.0}),\n",
       " (0, 13, {'weight': 1.0}),\n",
       " (0, 17, {'weight': 1.0}),\n",
       " (0, 19, {'weight': 1.0}),\n",
       " (0, 21, {'weight': 1.0}),\n",
       " (0, 31, {'weight': 1.0}),\n",
       " (1, 0, {'weight': 1.0}),\n",
       " (1, 2, {'weight': 1.0}),\n",
       " (1, 3, {'weight': 1.0}),\n",
       " (1, 7, {'weight': 1.0}),\n",
       " (1, 13, {'weight': 1.0}),\n",
       " (1, 17, {'weight': 1.0}),\n",
       " (1, 19, {'weight': 1.0}),\n",
       " (1, 21, {'weight': 1.0}),\n",
       " (1, 30, {'weight': 1.0}),\n",
       " (2, 0, {'weight': 1.0}),\n",
       " (2, 1, {'weight': 1.0}),\n",
       " (2, 3, {'weight': 1.0}),\n",
       " (2, 32, {'weight': 1.0}),\n",
       " (2, 7, {'weight': 1.0}),\n",
       " (2, 8, {'weight': 1.0}),\n",
       " (2, 9, {'weight': 1.0}),\n",
       " (2, 13, {'weight': 1.0}),\n",
       " (2, 27, {'weight': 1.0}),\n",
       " (2, 28, {'weight': 1.0}),\n",
       " (3, 0, {'weight': 1.0}),\n",
       " (3, 1, {'weight': 1.0}),\n",
       " (3, 2, {'weight': 1.0}),\n",
       " (3, 7, {'weight': 1.0}),\n",
       " (3, 12, {'weight': 1.0}),\n",
       " (3, 13, {'weight': 1.0}),\n",
       " (4, 0, {'weight': 1.0}),\n",
       " (4, 10, {'weight': 1.0}),\n",
       " (4, 6, {'weight': 1.0}),\n",
       " (5, 0, {'weight': 1.0}),\n",
       " (5, 16, {'weight': 1.0}),\n",
       " (5, 10, {'weight': 1.0}),\n",
       " (5, 6, {'weight': 1.0}),\n",
       " (6, 0, {'weight': 1.0}),\n",
       " (6, 16, {'weight': 1.0}),\n",
       " (6, 4, {'weight': 1.0}),\n",
       " (6, 5, {'weight': 1.0}),\n",
       " (7, 0, {'weight': 1.0}),\n",
       " (7, 1, {'weight': 1.0}),\n",
       " (7, 2, {'weight': 1.0}),\n",
       " (7, 3, {'weight': 1.0}),\n",
       " (8, 0, {'weight': 1.0}),\n",
       " (8, 32, {'weight': 1.0}),\n",
       " (8, 2, {'weight': 1.0}),\n",
       " (8, 30, {'weight': 1.0}),\n",
       " (8, 33, {'weight': 1.0}),\n",
       " (9, 33, {'weight': 1.0}),\n",
       " (9, 2, {'weight': 1.0}),\n",
       " (10, 0, {'weight': 1.0}),\n",
       " (10, 4, {'weight': 1.0}),\n",
       " (10, 5, {'weight': 1.0}),\n",
       " (11, 0, {'weight': 1.0}),\n",
       " (12, 0, {'weight': 1.0}),\n",
       " (12, 3, {'weight': 1.0}),\n",
       " (13, 0, {'weight': 1.0}),\n",
       " (13, 1, {'weight': 1.0}),\n",
       " (13, 2, {'weight': 1.0}),\n",
       " (13, 3, {'weight': 1.0}),\n",
       " (13, 33, {'weight': 1.0}),\n",
       " (14, 32, {'weight': 1.0}),\n",
       " (14, 33, {'weight': 1.0}),\n",
       " (15, 32, {'weight': 1.0}),\n",
       " (15, 33, {'weight': 1.0}),\n",
       " (16, 5, {'weight': 1.0}),\n",
       " (16, 6, {'weight': 1.0}),\n",
       " (17, 0, {'weight': 1.0}),\n",
       " (17, 1, {'weight': 1.0}),\n",
       " (18, 32, {'weight': 1.0}),\n",
       " (18, 33, {'weight': 1.0}),\n",
       " (19, 0, {'weight': 1.0}),\n",
       " (19, 1, {'weight': 1.0}),\n",
       " (19, 33, {'weight': 1.0}),\n",
       " (20, 32, {'weight': 1.0}),\n",
       " (20, 33, {'weight': 1.0}),\n",
       " (21, 0, {'weight': 1.0}),\n",
       " (21, 1, {'weight': 1.0}),\n",
       " (22, 32, {'weight': 1.0}),\n",
       " (22, 33, {'weight': 1.0}),\n",
       " (23, 32, {'weight': 1.0}),\n",
       " (23, 25, {'weight': 1.0}),\n",
       " (23, 27, {'weight': 1.0}),\n",
       " (23, 29, {'weight': 1.0}),\n",
       " (23, 33, {'weight': 1.0}),\n",
       " (24, 25, {'weight': 1.0}),\n",
       " (24, 27, {'weight': 1.0}),\n",
       " (24, 31, {'weight': 1.0}),\n",
       " (25, 24, {'weight': 1.0}),\n",
       " (25, 23, {'weight': 1.0}),\n",
       " (25, 31, {'weight': 1.0}),\n",
       " (26, 33, {'weight': 1.0}),\n",
       " (26, 29, {'weight': 1.0}),\n",
       " (27, 24, {'weight': 1.0}),\n",
       " (27, 33, {'weight': 1.0}),\n",
       " (27, 2, {'weight': 1.0}),\n",
       " (27, 23, {'weight': 1.0}),\n",
       " (28, 33, {'weight': 1.0}),\n",
       " (28, 2, {'weight': 1.0}),\n",
       " (28, 31, {'weight': 1.0}),\n",
       " (29, 32, {'weight': 1.0}),\n",
       " (29, 33, {'weight': 1.0}),\n",
       " (29, 26, {'weight': 1.0}),\n",
       " (29, 23, {'weight': 1.0}),\n",
       " (30, 8, {'weight': 1.0}),\n",
       " (30, 1, {'weight': 1.0}),\n",
       " (30, 32, {'weight': 1.0}),\n",
       " (30, 33, {'weight': 1.0}),\n",
       " (31, 0, {'weight': 1.0}),\n",
       " (31, 33, {'weight': 1.0}),\n",
       " (31, 32, {'weight': 1.0}),\n",
       " (31, 24, {'weight': 1.0}),\n",
       " (31, 25, {'weight': 1.0}),\n",
       " (31, 28, {'weight': 1.0}),\n",
       " (32, 33, {'weight': 1.0}),\n",
       " (32, 2, {'weight': 1.0}),\n",
       " (32, 8, {'weight': 1.0}),\n",
       " (32, 14, {'weight': 1.0}),\n",
       " (32, 15, {'weight': 1.0}),\n",
       " (32, 18, {'weight': 1.0}),\n",
       " (32, 20, {'weight': 1.0}),\n",
       " (32, 22, {'weight': 1.0}),\n",
       " (32, 23, {'weight': 1.0}),\n",
       " (32, 29, {'weight': 1.0}),\n",
       " (32, 30, {'weight': 1.0}),\n",
       " (32, 31, {'weight': 1.0}),\n",
       " (33, 32, {'weight': 1.0}),\n",
       " (33, 8, {'weight': 1.0}),\n",
       " (33, 9, {'weight': 1.0}),\n",
       " (33, 13, {'weight': 1.0}),\n",
       " (33, 14, {'weight': 1.0}),\n",
       " (33, 15, {'weight': 1.0}),\n",
       " (33, 18, {'weight': 1.0}),\n",
       " (33, 19, {'weight': 1.0}),\n",
       " (33, 20, {'weight': 1.0}),\n",
       " (33, 22, {'weight': 1.0}),\n",
       " (33, 23, {'weight': 1.0}),\n",
       " (33, 26, {'weight': 1.0}),\n",
       " (33, 27, {'weight': 1.0}),\n",
       " (33, 28, {'weight': 1.0}),\n",
       " (33, 29, {'weight': 1.0}),\n",
       " (33, 30, {'weight': 1.0}),\n",
       " (33, 31, {'weight': 1.0})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?SDNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda2/lib/python2.7/site-packages/gem/embedding/sdne_utils.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{m..., inputs=/input_13)`\n",
      "  encoder = Model(input=x, output=y[K])\n",
      "/home/david/miniconda2/lib/python2.7/site-packages/gem/embedding/sdne_utils.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{m..., inputs=/input_14)`\n",
      "  decoder = Model(input=y, output=x_hat)\n",
      "/home/david/miniconda2/lib/python2.7/site-packages/gem/embedding/sdne_utils.py:45: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Elemwise{..., inputs=/input_15)`\n",
      "  autoencoder = Model(input=x, output=[x_hat, y])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 3.1547 - merge_13_loss: 0.9630 - merge_14_loss: 0.9630 - merge_15_loss: 0.4171\n",
      "EPOCH 1/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 3.1476 - merge_13_loss: 0.9599 - merge_14_loss: 0.9599 - merge_15_loss: 0.4266\n",
      "EPOCH 2/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 3.1334 - merge_13_loss: 0.9534 - merge_14_loss: 0.9534 - merge_15_loss: 0.4408\n",
      "EPOCH 3/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 3.1135 - merge_13_loss: 0.9443 - merge_14_loss: 0.9443 - merge_15_loss: 0.4596\n",
      "EPOCH 4/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 3.0888 - merge_13_loss: 0.9329 - merge_14_loss: 0.9329 - merge_15_loss: 0.4827\n",
      "EPOCH 5/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 3.0595 - merge_13_loss: 0.9194 - merge_14_loss: 0.9194 - merge_15_loss: 0.5096\n",
      "EPOCH 6/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 3.0272 - merge_13_loss: 0.9046 - merge_14_loss: 0.9046 - merge_15_loss: 0.5397\n",
      "EPOCH 7/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.9921 - merge_13_loss: 0.8887 - merge_14_loss: 0.8887 - merge_15_loss: 0.5729\n",
      "EPOCH 8/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.9550 - merge_13_loss: 0.8719 - merge_14_loss: 0.8719 - merge_15_loss: 0.6088\n",
      "EPOCH 9/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.9178 - merge_13_loss: 0.8553 - merge_14_loss: 0.8553 - merge_15_loss: 0.6474\n",
      "EPOCH 10/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.8818 - merge_13_loss: 0.8394 - merge_14_loss: 0.8394 - merge_15_loss: 0.6874\n",
      "EPOCH 11/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.8470 - merge_13_loss: 0.8244 - merge_14_loss: 0.8244 - merge_15_loss: 0.7276\n",
      "EPOCH 12/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.8147 - merge_13_loss: 0.8107 - merge_14_loss: 0.8107 - merge_15_loss: 0.7684\n",
      "EPOCH 13/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.7851 - merge_13_loss: 0.7987 - merge_14_loss: 0.7987 - merge_15_loss: 0.8073\n",
      "EPOCH 14/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.7592 - merge_13_loss: 0.7887 - merge_14_loss: 0.7887 - merge_15_loss: 0.8390\n",
      "EPOCH 15/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.7374 - merge_13_loss: 0.7810 - merge_14_loss: 0.7810 - merge_15_loss: 0.8663\n",
      "EPOCH 16/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.7200 - merge_13_loss: 0.7756 - merge_14_loss: 0.7756 - merge_15_loss: 0.8932\n",
      "EPOCH 17/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.7063 - merge_13_loss: 0.7724 - merge_14_loss: 0.7724 - merge_15_loss: 0.9195\n",
      "EPOCH 18/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6957 - merge_13_loss: 0.7708 - merge_14_loss: 0.7708 - merge_15_loss: 0.9449\n",
      "EPOCH 19/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6874 - merge_13_loss: 0.7706 - merge_14_loss: 0.7706 - merge_15_loss: 0.9699\n",
      "EPOCH 20/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6802 - merge_13_loss: 0.7711 - merge_14_loss: 0.7711 - merge_15_loss: 0.9937\n",
      "EPOCH 21/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6740 - merge_13_loss: 0.7722 - merge_14_loss: 0.7722 - merge_15_loss: 1.0157\n",
      "EPOCH 22/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6682 - merge_13_loss: 0.7737 - merge_14_loss: 0.7737 - merge_15_loss: 1.0377\n",
      "EPOCH 23/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6623 - merge_13_loss: 0.7753 - merge_14_loss: 0.7753 - merge_15_loss: 1.0614\n",
      "EPOCH 24/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6557 - merge_13_loss: 0.7766 - merge_14_loss: 0.7766 - merge_15_loss: 1.0874\n",
      "EPOCH 25/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6475 - merge_13_loss: 0.7773 - merge_14_loss: 0.7773 - merge_15_loss: 1.1173\n",
      "EPOCH 26/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6373 - merge_13_loss: 0.7771 - merge_14_loss: 0.7771 - merge_15_loss: 1.1509\n",
      "EPOCH 27/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6248 - merge_13_loss: 0.7758 - merge_14_loss: 0.7758 - merge_15_loss: 1.1876\n",
      "EPOCH 28/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.6106 - merge_13_loss: 0.7737 - merge_14_loss: 0.7737 - merge_15_loss: 1.2283\n",
      "EPOCH 29/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.5942 - merge_13_loss: 0.7706 - merge_14_loss: 0.7706 - merge_15_loss: 1.2743\n",
      "EPOCH 30/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.5756 - merge_13_loss: 0.7665 - merge_14_loss: 0.7665 - merge_15_loss: 1.3256\n",
      "EPOCH 31/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.5551 - merge_13_loss: 0.7614 - merge_14_loss: 0.7614 - merge_15_loss: 1.3828\n",
      "EPOCH 32/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.5330 - merge_13_loss: 0.7556 - merge_14_loss: 0.7556 - merge_15_loss: 1.4465\n",
      "EPOCH 33/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.5104 - merge_13_loss: 0.7495 - merge_14_loss: 0.7495 - merge_15_loss: 1.5180\n",
      "EPOCH 34/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.4868 - merge_13_loss: 0.7429 - merge_14_loss: 0.7429 - merge_15_loss: 1.5956\n",
      "EPOCH 35/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.4627 - merge_13_loss: 0.7360 - merge_14_loss: 0.7360 - merge_15_loss: 1.6789\n",
      "EPOCH 36/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.4383 - merge_13_loss: 0.7290 - merge_14_loss: 0.7290 - merge_15_loss: 1.7672\n",
      "EPOCH 37/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.4141 - merge_13_loss: 0.7222 - merge_14_loss: 0.7222 - merge_15_loss: 1.8597\n",
      "EPOCH 38/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.3901 - merge_13_loss: 0.7154 - merge_14_loss: 0.7154 - merge_15_loss: 1.9634\n",
      "EPOCH 39/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.3665 - merge_13_loss: 0.7089 - merge_14_loss: 0.7089 - merge_15_loss: 2.0705\n",
      "EPOCH 40/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.3438 - merge_13_loss: 0.7029 - merge_14_loss: 0.7029 - merge_15_loss: 2.1762\n",
      "EPOCH 41/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.3219 - merge_13_loss: 0.6972 - merge_14_loss: 0.6972 - merge_15_loss: 2.2765\n",
      "EPOCH 42/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.3006 - merge_13_loss: 0.6920 - merge_14_loss: 0.6920 - merge_15_loss: 2.3696\n",
      "EPOCH 43/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.2802 - merge_13_loss: 0.6873 - merge_14_loss: 0.6873 - merge_15_loss: 2.4530\n",
      "EPOCH 44/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.2608 - merge_13_loss: 0.6832 - merge_14_loss: 0.6832 - merge_15_loss: 2.5223\n",
      "EPOCH 45/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.2427 - merge_13_loss: 0.6799 - merge_14_loss: 0.6799 - merge_15_loss: 2.5740\n",
      "EPOCH 46/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.2248 - merge_13_loss: 0.6768 - merge_14_loss: 0.6768 - merge_15_loss: 2.6054\n",
      "EPOCH 47/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.2070 - merge_13_loss: 0.6739 - merge_14_loss: 0.6739 - merge_15_loss: 2.6137\n",
      "EPOCH 48/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.1894 - merge_13_loss: 0.6713 - merge_14_loss: 0.6713 - merge_15_loss: 2.5991\n",
      "EPOCH 49/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.1723 - merge_13_loss: 0.6690 - merge_14_loss: 0.6690 - merge_15_loss: 2.5643\n",
      "EPOCH 50/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.1558 - merge_13_loss: 0.6672 - merge_14_loss: 0.6672 - merge_15_loss: 2.5195\n",
      "EPOCH 51/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.1402 - merge_13_loss: 0.6659 - merge_14_loss: 0.6659 - merge_15_loss: 2.4716\n",
      "EPOCH 52/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.1253 - merge_13_loss: 0.6650 - merge_14_loss: 0.6650 - merge_15_loss: 2.4138\n",
      "EPOCH 53/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.1109 - merge_13_loss: 0.6643 - merge_14_loss: 0.6643 - merge_15_loss: 2.3500\n",
      "EPOCH 54/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.0970 - merge_13_loss: 0.6639 - merge_14_loss: 0.6639 - merge_15_loss: 2.2829\n",
      "EPOCH 55/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.0836 - merge_13_loss: 0.6637 - merge_14_loss: 0.6637 - merge_15_loss: 2.2163\n",
      "EPOCH 56/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.0705 - merge_13_loss: 0.6636 - merge_14_loss: 0.6636 - merge_15_loss: 2.1524\n",
      "EPOCH 57/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.0576 - merge_13_loss: 0.6634 - merge_14_loss: 0.6634 - merge_15_loss: 2.0934\n",
      "EPOCH 58/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.0445 - merge_13_loss: 0.6629 - merge_14_loss: 0.6629 - merge_15_loss: 2.0417\n",
      "EPOCH 59/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.0317 - merge_13_loss: 0.6623 - merge_14_loss: 0.6623 - merge_15_loss: 1.9988\n",
      "EPOCH 60/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.0189 - merge_13_loss: 0.6616 - merge_14_loss: 0.6616 - merge_15_loss: 1.9639\n",
      "EPOCH 61/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 2.0058 - merge_13_loss: 0.6606 - merge_14_loss: 0.6606 - merge_15_loss: 1.9394\n",
      "EPOCH 62/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.9922 - merge_13_loss: 0.6591 - merge_14_loss: 0.6591 - merge_15_loss: 1.9241\n",
      "EPOCH 63/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.9781 - merge_13_loss: 0.6574 - merge_14_loss: 0.6574 - merge_15_loss: 1.9175\n",
      "EPOCH 64/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.9632 - merge_13_loss: 0.6551 - merge_14_loss: 0.6551 - merge_15_loss: 1.9155\n",
      "EPOCH 65/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.9477 - merge_13_loss: 0.6524 - merge_14_loss: 0.6524 - merge_15_loss: 1.9152\n",
      "EPOCH 66/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.9316 - merge_13_loss: 0.6492 - merge_14_loss: 0.6492 - merge_15_loss: 1.9190\n",
      "EPOCH 67/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.9152 - merge_13_loss: 0.6458 - merge_14_loss: 0.6458 - merge_15_loss: 1.9273\n",
      "EPOCH 68/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.8983 - merge_13_loss: 0.6419 - merge_14_loss: 0.6419 - merge_15_loss: 1.9397\n",
      "EPOCH 69/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.8817 - merge_13_loss: 0.6381 - merge_14_loss: 0.6381 - merge_15_loss: 1.9530\n",
      "EPOCH 70/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.8658 - merge_13_loss: 0.6343 - merge_14_loss: 0.6343 - merge_15_loss: 1.9687\n",
      "EPOCH 71/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.8498 - merge_13_loss: 0.6303 - merge_14_loss: 0.6303 - merge_15_loss: 1.9854\n",
      "EPOCH 72/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.8336 - merge_13_loss: 0.6261 - merge_14_loss: 0.6261 - merge_15_loss: 2.0016\n",
      "EPOCH 73/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.8173 - merge_13_loss: 0.6219 - merge_14_loss: 0.6219 - merge_15_loss: 2.0157\n",
      "EPOCH 74/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.8007 - merge_13_loss: 0.6173 - merge_14_loss: 0.6173 - merge_15_loss: 2.0289\n",
      "EPOCH 75/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.7843 - merge_13_loss: 0.6128 - merge_14_loss: 0.6128 - merge_15_loss: 2.0389\n",
      "EPOCH 76/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.7684 - merge_13_loss: 0.6083 - merge_14_loss: 0.6083 - merge_15_loss: 2.0454\n",
      "EPOCH 77/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.7528 - merge_13_loss: 0.6038 - merge_14_loss: 0.6038 - merge_15_loss: 2.0472\n",
      "EPOCH 78/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.7374 - merge_13_loss: 0.5993 - merge_14_loss: 0.5993 - merge_15_loss: 2.0455\n",
      "EPOCH 79/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.7219 - merge_13_loss: 0.5948 - merge_14_loss: 0.5948 - merge_15_loss: 2.0367\n",
      "EPOCH 80/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.7071 - merge_13_loss: 0.5905 - merge_14_loss: 0.5905 - merge_15_loss: 2.0238\n",
      "EPOCH 81/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6932 - merge_13_loss: 0.5864 - merge_14_loss: 0.5864 - merge_15_loss: 2.0096\n",
      "EPOCH 82/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6804 - merge_13_loss: 0.5826 - merge_14_loss: 0.5826 - merge_15_loss: 1.9934\n",
      "EPOCH 83/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6686 - merge_13_loss: 0.5793 - merge_14_loss: 0.5793 - merge_15_loss: 1.9760\n",
      "EPOCH 84/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6579 - merge_13_loss: 0.5764 - merge_14_loss: 0.5764 - merge_15_loss: 1.9589\n",
      "EPOCH 85/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6482 - merge_13_loss: 0.5740 - merge_14_loss: 0.5740 - merge_15_loss: 1.9424\n",
      "EPOCH 86/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6395 - merge_13_loss: 0.5719 - merge_14_loss: 0.5719 - merge_15_loss: 1.9289\n",
      "EPOCH 87/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6316 - merge_13_loss: 0.5700 - merge_14_loss: 0.5700 - merge_15_loss: 1.9169\n",
      "EPOCH 88/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6240 - merge_13_loss: 0.5681 - merge_14_loss: 0.5681 - merge_15_loss: 1.9051\n",
      "EPOCH 89/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6166 - merge_13_loss: 0.5662 - merge_14_loss: 0.5662 - merge_15_loss: 1.8944\n",
      "EPOCH 90/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6093 - merge_13_loss: 0.5641 - merge_14_loss: 0.5641 - merge_15_loss: 1.8841\n",
      "EPOCH 91/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.6019 - merge_13_loss: 0.5618 - merge_14_loss: 0.5618 - merge_15_loss: 1.8734\n",
      "EPOCH 92/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5943 - merge_13_loss: 0.5592 - merge_14_loss: 0.5592 - merge_15_loss: 1.8633\n",
      "EPOCH 93/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5866 - merge_13_loss: 0.5563 - merge_14_loss: 0.5563 - merge_15_loss: 1.8533\n",
      "EPOCH 94/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5787 - merge_13_loss: 0.5529 - merge_14_loss: 0.5529 - merge_15_loss: 1.8435\n",
      "EPOCH 95/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5700 - merge_13_loss: 0.5492 - merge_14_loss: 0.5492 - merge_15_loss: 1.8325\n",
      "EPOCH 96/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5611 - merge_13_loss: 0.5450 - merge_14_loss: 0.5450 - merge_15_loss: 1.8202\n",
      "EPOCH 97/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5516 - merge_13_loss: 0.5404 - merge_14_loss: 0.5404 - merge_15_loss: 1.8061\n",
      "EPOCH 98/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5423 - merge_13_loss: 0.5355 - merge_14_loss: 0.5355 - merge_15_loss: 1.7909\n",
      "EPOCH 99/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5332 - merge_13_loss: 0.5306 - merge_14_loss: 0.5306 - merge_15_loss: 1.7735\n",
      "EPOCH 100/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5245 - merge_13_loss: 0.5257 - merge_14_loss: 0.5257 - merge_15_loss: 1.7545\n",
      "EPOCH 101/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5163 - merge_13_loss: 0.5209 - merge_14_loss: 0.5209 - merge_15_loss: 1.7348\n",
      "EPOCH 102/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5086 - merge_13_loss: 0.5161 - merge_14_loss: 0.5161 - merge_15_loss: 1.7135\n",
      "EPOCH 103/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5014 - merge_13_loss: 0.5116 - merge_14_loss: 0.5116 - merge_15_loss: 1.6900\n",
      "EPOCH 104/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4950 - merge_13_loss: 0.5072 - merge_14_loss: 0.5072 - merge_15_loss: 1.6667\n",
      "EPOCH 105/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4893 - merge_13_loss: 0.5032 - merge_14_loss: 0.5032 - merge_15_loss: 1.6442\n",
      "EPOCH 106/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4850 - merge_13_loss: 0.4995 - merge_14_loss: 0.4995 - merge_15_loss: 1.6232\n",
      "EPOCH 107/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4821 - merge_13_loss: 0.4963 - merge_14_loss: 0.4963 - merge_15_loss: 1.6037\n",
      "EPOCH 108/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4803 - merge_13_loss: 0.4936 - merge_14_loss: 0.4936 - merge_15_loss: 1.5864\n",
      "EPOCH 109/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4794 - merge_13_loss: 0.4911 - merge_14_loss: 0.4911 - merge_15_loss: 1.5720\n",
      "EPOCH 110/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4795 - merge_13_loss: 0.4890 - merge_14_loss: 0.4890 - merge_15_loss: 1.5603\n",
      "EPOCH 111/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4805 - merge_13_loss: 0.4874 - merge_14_loss: 0.4874 - merge_15_loss: 1.5516\n",
      "EPOCH 112/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4827 - merge_13_loss: 0.4861 - merge_14_loss: 0.4861 - merge_15_loss: 1.5446\n",
      "EPOCH 113/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4852 - merge_13_loss: 0.4850 - merge_14_loss: 0.4850 - merge_15_loss: 1.5411\n",
      "EPOCH 114/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4883 - merge_13_loss: 0.4840 - merge_14_loss: 0.4840 - merge_15_loss: 1.5408\n",
      "EPOCH 115/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4912 - merge_13_loss: 0.4831 - merge_14_loss: 0.4831 - merge_15_loss: 1.5421\n",
      "EPOCH 116/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4940 - merge_13_loss: 0.4821 - merge_14_loss: 0.4821 - merge_15_loss: 1.5444\n",
      "EPOCH 117/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4964 - merge_13_loss: 0.4808 - merge_14_loss: 0.4808 - merge_15_loss: 1.5490\n",
      "EPOCH 118/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4980 - merge_13_loss: 0.4793 - merge_14_loss: 0.4793 - merge_15_loss: 1.5547\n",
      "EPOCH 119/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.4992 - merge_13_loss: 0.4776 - merge_14_loss: 0.4776 - merge_15_loss: 1.5614\n",
      "EPOCH 120/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5002 - merge_13_loss: 0.4758 - merge_14_loss: 0.4758 - merge_15_loss: 1.5667\n",
      "EPOCH 121/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5011 - merge_13_loss: 0.4741 - merge_14_loss: 0.4741 - merge_15_loss: 1.5723\n",
      "EPOCH 122/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5019 - merge_13_loss: 0.4723 - merge_14_loss: 0.4723 - merge_15_loss: 1.5796\n",
      "EPOCH 123/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5027 - merge_13_loss: 0.4707 - merge_14_loss: 0.4707 - merge_15_loss: 1.5873\n",
      "EPOCH 124/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5039 - merge_13_loss: 0.4691 - merge_14_loss: 0.4691 - merge_15_loss: 1.5965\n",
      "EPOCH 125/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5052 - merge_13_loss: 0.4677 - merge_14_loss: 0.4677 - merge_15_loss: 1.6068\n",
      "EPOCH 126/10000\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s - loss: 1.5065 - merge_13_loss: 0.4663 - merge_14_loss: 0.4663 - merge_15_loss: 1.6190"
     ]
    }
   ],
   "source": [
    "from gem.embedding.sdne import SDNE\n",
    "\n",
    "sdne = SDNE(d=2, beta=1, alpha=1e-2, nu1=1e-3, nu2=1e-3, K=2, n_units=[15,],\n",
    "            rho=0.3, n_iter=10000, xeta=0.01, n_batch=500)\n",
    "\n",
    "Y, t = sdne.learn_embedding(graph, edge_f=None, is_weighted=True, no_python=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colours = np.array([\"r\" if club ==  \"Mr. Hi\" else \"b\" for club in nx.get_node_attributes(graph, \"club\").values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(Y[:,0], Y[:,1], c =colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
